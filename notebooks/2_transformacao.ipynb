{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e09ed64",
   "metadata": {},
   "source": [
    "# üîÑ Transforma√ß√£o de Dados - Seguran√ßa P√∫blica SP\n",
    "\n",
    "Este notebook realiza a **transforma√ß√£o** dos dados brutos extra√≠dos do portal da SSP-SP.\n",
    "\n",
    "## Objetivos:\n",
    "- Carregar CSVs brutos de `data/raw/`\n",
    "- Padronizar nomes de colunas\n",
    "- Limpar e tratar dados\n",
    "- Criar coluna `taxa_crime_por_100k`\n",
    "- Categorizar tipos de crime\n",
    "- Salvar dados processados em `data/processed/`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6013244f",
   "metadata": {},
   "source": [
    "## 1. Importar Bibliotecas e Fun√ß√µes de Transforma√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d3abf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necess√°rias\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Adicionar o diret√≥rio src ao path\n",
    "sys.path.append(str(Path().resolve().parent / 'src'))\n",
    "\n",
    "# Importar fun√ß√µes de transforma√ß√£o\n",
    "from transform import (\n",
    "    clean_column_names,\n",
    "    remove_duplicates,\n",
    "    handle_missing_values,\n",
    "    normalize_dates,\n",
    "    categorize_crimes,\n",
    "    aggregate_by_region,\n",
    "    calculate_crime_rate,\n",
    "    validate_data\n",
    ")\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Bibliotecas e fun√ß√µes de transforma√ß√£o importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75544ad6",
   "metadata": {},
   "source": [
    "## 2. Configurar Diret√≥rios e Caminhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009b712e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir diret√≥rios do projeto\n",
    "PROJECT_ROOT = Path().resolve().parent\n",
    "DATA_RAW_DIR = PROJECT_ROOT / 'data' / 'raw'\n",
    "DATA_PROCESSED_DIR = PROJECT_ROOT / 'data' / 'processed'\n",
    "DATA_INTERIM_DIR = PROJECT_ROOT / 'data' / 'interim'\n",
    "\n",
    "# Criar diret√≥rios se n√£o existirem\n",
    "DATA_PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_INTERIM_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Diret√≥rio de dados brutos: {DATA_RAW_DIR}\")\n",
    "print(f\"üìÅ Diret√≥rio de dados processados: {DATA_PROCESSED_DIR}\")\n",
    "print(f\"üìÅ Diret√≥rio de dados intermedi√°rios: {DATA_INTERIM_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa9cb9d",
   "metadata": {},
   "source": [
    "## 3. Carregar Dados Brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da5734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar arquivos CSV dispon√≠veis em data/raw\n",
    "csv_files = list(DATA_RAW_DIR.glob('*.csv'))\n",
    "\n",
    "print(f\"üìÇ Arquivos CSV encontrados em data/raw/: {len(csv_files)}\\n\")\n",
    "for i, file in enumerate(csv_files, 1):\n",
    "    size_kb = file.stat().st_size / 1024\n",
    "    print(f\"  {i}. {file.name} ({size_kb:.2f} KB)\")\n",
    "\n",
    "# Carregar o arquivo de exemplo criado no notebook de extra√ß√£o\n",
    "arquivo_exemplo = DATA_RAW_DIR / \"exemplo_dados_ssp_2024.csv\"\n",
    "\n",
    "if arquivo_exemplo.exists():\n",
    "    df_raw = pd.read_csv(arquivo_exemplo, sep=';', encoding='utf-8-sig')\n",
    "    print(f\"\\n‚úÖ Arquivo carregado: {arquivo_exemplo.name}\")\n",
    "    print(f\"üìä Dimens√µes: {df_raw.shape[0]} linhas x {df_raw.shape[1]} colunas\")\n",
    "    print(f\"\\nüìã Primeiras 5 linhas:\")\n",
    "    display(df_raw.head())\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Arquivo de exemplo n√£o encontrado!\")\n",
    "    print(\"Execute primeiro o notebook '1_extracao.ipynb'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b422bfaa",
   "metadata": {},
   "source": [
    "## 4. Etapa 1: Padronizar Nomes de Colunas\n",
    "\n",
    "Usando a fun√ß√£o `clean_column_names()` para:\n",
    "- Converter para min√∫sculas\n",
    "- Remover acentos\n",
    "- Substituir espa√ßos por underscores\n",
    "- Remover caracteres especiais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd0a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar nomes de colunas antes da transforma√ß√£o\n",
    "print(\"üìã Colunas ANTES da padroniza√ß√£o:\")\n",
    "print(df_raw.columns.tolist())\n",
    "\n",
    "# Aplicar fun√ß√£o de limpeza de nomes de colunas\n",
    "df_transformed = clean_column_names(df_raw)\n",
    "\n",
    "print(\"\\n‚úÖ Colunas AP√ìS a padroniza√ß√£o:\")\n",
    "print(df_transformed.columns.tolist())\n",
    "\n",
    "# Compara√ß√£o lado a lado\n",
    "print(\"\\nüìä Compara√ß√£o:\")\n",
    "for old, new in zip(df_raw.columns, df_transformed.columns):\n",
    "    if old != new:\n",
    "        print(f\"  {old:<20} ‚Üí {new}\")\n",
    "    else:\n",
    "        print(f\"  {old:<20} (sem altera√ß√£o)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Padroniza√ß√£o de nomes de colunas conclu√≠da!\")\n",
    "df_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f86558",
   "metadata": {},
   "source": [
    "## 5. Etapa 2: Remover Duplicatas\n",
    "\n",
    "Usando a fun√ß√£o `remove_duplicates()` para identificar e remover registros duplicados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d910384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar duplicatas antes da remo√ß√£o\n",
    "duplicatas_antes = df_transformed.duplicated().sum()\n",
    "print(f\"üîç Registros duplicados encontrados: {duplicatas_antes}\")\n",
    "\n",
    "# Remover duplicatas\n",
    "registros_antes = len(df_transformed)\n",
    "df_transformed = remove_duplicates(df_transformed)\n",
    "registros_depois = len(df_transformed)\n",
    "\n",
    "print(f\"\\nüìä Registros ANTES: {registros_antes:,}\")\n",
    "print(f\"üìä Registros DEPOIS: {registros_depois:,}\")\n",
    "print(f\"üóëÔ∏è  Registros removidos: {registros_antes - registros_depois:,}\")\n",
    "\n",
    "if registros_antes == registros_depois:\n",
    "    print(\"\\n‚úÖ Nenhuma duplicata encontrada!\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ {registros_antes - registros_depois} duplicatas removidas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11861591",
   "metadata": {},
   "source": [
    "## 6. Etapa 3: Tratar Valores Ausentes\n",
    "\n",
    "Usando a fun√ß√£o `handle_missing_values()` com diferentes estrat√©gias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a606a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar valores ausentes\n",
    "print(\"üîç Valores ausentes por coluna:\")\n",
    "valores_nulos = df_transformed.isnull().sum()\n",
    "print(valores_nulos)\n",
    "\n",
    "total_nulos = valores_nulos.sum()\n",
    "print(f\"\\nüìä Total de valores ausentes: {total_nulos}\")\n",
    "\n",
    "if total_nulos > 0:\n",
    "    # Aplicar estrat√©gia de preenchimento com zero (para dados de criminalidade)\n",
    "    # Pode usar 'drop', 'fill_zero', 'fill_mean', 'fill_median'\n",
    "    df_transformed = handle_missing_values(df_transformed, strategy='fill_zero')\n",
    "    print(\"\\n‚úÖ Valores ausentes preenchidos com zero\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Nenhum valor ausente encontrado!\")\n",
    "\n",
    "# Verificar novamente\n",
    "print(\"\\nüîç Verifica√ß√£o p√≥s-tratamento:\")\n",
    "print(df_transformed.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4466e216",
   "metadata": {},
   "source": [
    "## 7. Etapa 4: Categorizar Tipos de Crime\n",
    "\n",
    "Usando a fun√ß√£o `categorize_crimes()` para agrupar crimes em categorias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54911f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar tipos de crime √∫nicos\n",
    "print(\"üîç Tipos de crime √∫nicos no dataset:\")\n",
    "print(df_transformed['tipo_crime'].unique())\n",
    "print(f\"\\nTotal de tipos diferentes: {df_transformed['tipo_crime'].nunique()}\")\n",
    "\n",
    "# Aplicar categoriza√ß√£o\n",
    "df_transformed = categorize_crimes(df_transformed, crime_column='tipo_crime')\n",
    "\n",
    "# Verificar distribui√ß√£o por categoria\n",
    "print(\"\\nüìä Distribui√ß√£o por Categoria de Crime:\")\n",
    "distribuicao = df_transformed.groupby('categoria_crime').agg({\n",
    "    'ocorrencias': 'sum',\n",
    "    'vitimas': 'sum'\n",
    "}).sort_values('ocorrencias', ascending=False)\n",
    "\n",
    "print(distribuicao)\n",
    "\n",
    "# Visualizar\n",
    "print(f\"\\n‚úÖ Nova coluna 'categoria_crime' criada!\")\n",
    "print(f\"\\nüìã Amostra dos dados:\")\n",
    "df_transformed[['tipo_crime', 'categoria_crime', 'ocorrencias']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67b2917",
   "metadata": {},
   "source": [
    "## 8. Etapa 5: Criar Coluna Taxa de Crime por 100k Habitantes\n",
    "\n",
    "Usando a fun√ß√£o `calculate_crime_rate()` para calcular a taxa de criminalidade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e52beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar dataset de popula√ß√£o (dados aproximados para demonstra√ß√£o)\n",
    "# Em produ√ß√£o, voc√™ carregaria dados reais do IBGE ou outra fonte oficial\n",
    "\n",
    "populacao_sp = {\n",
    "    'municipio': ['S√£o Paulo', 'Campinas', 'Santos', 'Guarulhos', 'Ribeir√£o Preto'],\n",
    "    'populacao': [12396372, 1223237, 433153, 1291771, 711825]  # Dados aproximados\n",
    "}\n",
    "\n",
    "df_populacao = pd.DataFrame(populacao_sp)\n",
    "\n",
    "print(\"üìä Dados de Popula√ß√£o:\")\n",
    "print(df_populacao)\n",
    "print()\n",
    "\n",
    "# Verificar munic√≠pios antes do merge\n",
    "print(f\"üîç Munic√≠pios no dataset de criminalidade: {df_transformed['municipio'].unique()}\")\n",
    "print(f\"üîç Munic√≠pios no dataset de popula√ß√£o: {df_populacao['municipio'].unique()}\")\n",
    "\n",
    "# Aplicar c√°lculo de taxa de criminalidade\n",
    "df_transformed = calculate_crime_rate(df_transformed, df_populacao)\n",
    "\n",
    "print(\"\\n‚úÖ Coluna 'taxa_criminalidade' criada!\")\n",
    "print(f\"\\nüìã Amostra com as novas colunas:\")\n",
    "df_transformed[['municipio', 'tipo_crime', 'ocorrencias', 'populacao', 'taxa_criminalidade']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8eca66",
   "metadata": {},
   "source": [
    "## 9. Valida√ß√£o dos Dados Transformados\n",
    "\n",
    "Usando a fun√ß√£o `validate_data()` para verificar a integridade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15c965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validar dados transformados\n",
    "validation_results = validate_data(df_transformed)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üìä RELAT√ìRIO DE VALIDA√á√ÉO DOS DADOS TRANSFORMADOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n1Ô∏è‚É£ Total de Registros: {validation_results['total_registros']:,}\")\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£ Total de Colunas: {len(validation_results['colunas'])}\")\n",
    "print(\"   Colunas:\", \", \".join(validation_results['colunas']))\n",
    "\n",
    "print(f\"\\n3Ô∏è‚É£ Valores Nulos:\")\n",
    "if sum(validation_results['valores_nulos'].values()) == 0:\n",
    "    print(\"   ‚úÖ Nenhum valor nulo encontrado!\")\n",
    "else:\n",
    "    for col, count in validation_results['valores_nulos'].items():\n",
    "        if count > 0:\n",
    "            print(f\"   - {col}: {count}\")\n",
    "\n",
    "print(f\"\\n4Ô∏è‚É£ Duplicatas: {validation_results['duplicatas']}\")\n",
    "\n",
    "print(f\"\\n5Ô∏è‚É£ Estat√≠sticas Descritivas:\")\n",
    "print(df_transformed[['ocorrencias', 'vitimas', 'taxa_criminalidade']].describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1779ee4",
   "metadata": {},
   "source": [
    "## 10. Visualiza√ß√£o dos Dados Transformados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce085f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configurar estilo\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (16, 10)\n",
    "\n",
    "# Criar visualiza√ß√µes\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# Gr√°fico 1: Taxa de Criminalidade por Munic√≠pio\n",
    "taxa_por_municipio = df_transformed.groupby('municipio')['taxa_criminalidade'].mean().sort_values(ascending=True)\n",
    "taxa_por_municipio.plot(kind='barh', ax=axes[0, 0], color='darkred')\n",
    "axes[0, 0].set_title('Taxa de Criminalidade M√©dia por Munic√≠pio (por 100k hab)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Taxa por 100k habitantes', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Munic√≠pio', fontsize=11)\n",
    "\n",
    "# Gr√°fico 2: Distribui√ß√£o por Categoria de Crime\n",
    "categoria_crimes = df_transformed.groupby('categoria_crime')['ocorrencias'].sum().sort_values(ascending=False)\n",
    "colors = ['#e74c3c', '#3498db', '#f39c12', '#2ecc71']\n",
    "axes[0, 1].pie(categoria_crimes, labels=categoria_crimes.index, autopct='%1.1f%%', \n",
    "               colors=colors, startangle=90)\n",
    "axes[0, 1].set_title('Distribui√ß√£o por Categoria de Crime', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Gr√°fico 3: Top 10 Tipos de Crime\n",
    "top_crimes = df_transformed.groupby('tipo_crime')['ocorrencias'].sum().sort_values(ascending=False).head(10)\n",
    "top_crimes.plot(kind='bar', ax=axes[1, 0], color='steelblue')\n",
    "axes[1, 0].set_title('Top 10 Tipos de Crime (Total de Ocorr√™ncias)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Tipo de Crime', fontsize=11)\n",
    "axes[1, 0].set_ylabel('N√∫mero de Ocorr√™ncias', fontsize=11)\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Gr√°fico 4: Evolu√ß√£o Mensal\n",
    "evolucao_mensal = df_transformed.groupby('mes')['ocorrencias'].sum()\n",
    "axes[1, 1].plot(evolucao_mensal.index, evolucao_mensal.values, marker='o', \n",
    "                linewidth=2.5, markersize=8, color='darkgreen')\n",
    "axes[1, 1].fill_between(evolucao_mensal.index, evolucao_mensal.values, alpha=0.3, color='lightgreen')\n",
    "axes[1, 1].set_title('Evolu√ß√£o Mensal de Ocorr√™ncias', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('M√™s', fontsize=11)\n",
    "axes[1, 1].set_ylabel('N√∫mero de Ocorr√™ncias', fontsize=11)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_xticks(range(1, 11))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualiza√ß√µes criadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9847cfe0",
   "metadata": {},
   "source": [
    "## 11. Salvar Dados Processados em `data/processed/`\n",
    "\n",
    "Salvando os dados transformados em m√∫ltiplos formatos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5403b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir nome do arquivo de sa√≠da\n",
    "timestamp = datetime.now().strftime('%Y%m%d')\n",
    "output_filename = f\"dados_processados_ssp_{timestamp}\"\n",
    "\n",
    "# 1. Salvar em CSV\n",
    "csv_path = DATA_PROCESSED_DIR / f\"{output_filename}.csv\"\n",
    "df_transformed.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"‚úÖ CSV salvo: {csv_path}\")\n",
    "print(f\"   Tamanho: {csv_path.stat().st_size / 1024:.2f} KB\")\n",
    "\n",
    "# 2. Salvar em Parquet (mais eficiente)\n",
    "parquet_path = DATA_PROCESSED_DIR / f\"{output_filename}.parquet\"\n",
    "df_transformed.to_parquet(parquet_path, index=False)\n",
    "print(f\"\\n‚úÖ Parquet salvo: {parquet_path}\")\n",
    "print(f\"   Tamanho: {parquet_path.stat().st_size / 1024:.2f} KB\")\n",
    "\n",
    "# 3. Salvar vers√£o agregada por munic√≠pio\n",
    "df_agregado = aggregate_by_region(df_transformed, region_col='municipio')\n",
    "agregado_path = DATA_PROCESSED_DIR / f\"dados_agregados_municipio_{timestamp}.csv\"\n",
    "df_agregado.to_csv(agregado_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"\\n‚úÖ Dados agregados salvos: {agregado_path}\")\n",
    "print(f\"   Tamanho: {agregado_path.stat().st_size / 1024:.2f} KB\")\n",
    "\n",
    "print(f\"\\nüìä Total de registros processados: {len(df_transformed):,}\")\n",
    "print(f\"üìä Total de colunas: {len(df_transformed.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddcb83c",
   "metadata": {},
   "source": [
    "## 12. Salvar Metadados da Transforma√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f37d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Criar metadados da transforma√ß√£o\n",
    "metadata_transformacao = {\n",
    "    'data_processamento': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'notebook': '2_transformacao.ipynb',\n",
    "    'arquivo_origem': 'exemplo_dados_ssp_2024.csv',\n",
    "    'arquivos_saida': [\n",
    "        f\"{output_filename}.csv\",\n",
    "        f\"{output_filename}.parquet\",\n",
    "        f\"dados_agregados_municipio_{timestamp}.csv\"\n",
    "    ],\n",
    "    'transformacoes_aplicadas': [\n",
    "        'Padroniza√ß√£o de nomes de colunas',\n",
    "        'Remo√ß√£o de duplicatas',\n",
    "        'Tratamento de valores ausentes (fill_zero)',\n",
    "        'Categoriza√ß√£o de tipos de crime',\n",
    "        'C√°lculo de taxa de criminalidade por 100k habitantes',\n",
    "        'Agrega√ß√£o por munic√≠pio'\n",
    "    ],\n",
    "    'dados_processados': {\n",
    "        'total_registros': int(len(df_transformed)),\n",
    "        'total_colunas': int(len(df_transformed.columns)),\n",
    "        'colunas': list(df_transformed.columns),\n",
    "        'periodo': {\n",
    "            'ano': int(df_transformed['ano'].iloc[0]),\n",
    "            'mes_inicio': int(df_transformed['mes'].min()),\n",
    "            'mes_fim': int(df_transformed['mes'].max())\n",
    "        }\n",
    "    },\n",
    "    'qualidade': {\n",
    "        'valores_nulos': int(df_transformed.isnull().sum().sum()),\n",
    "        'duplicatas': int(df_transformed.duplicated().sum()),\n",
    "        'registros_validos': int(len(df_transformed))\n",
    "    },\n",
    "    'estatisticas': {\n",
    "        'total_ocorrencias': int(df_transformed['ocorrencias'].sum()),\n",
    "        'total_vitimas': int(df_transformed['vitimas'].sum()),\n",
    "        'taxa_media_criminalidade': float(df_transformed['taxa_criminalidade'].mean()),\n",
    "        'municipios_analisados': int(df_transformed['municipio'].nunique()),\n",
    "        'tipos_crime': int(df_transformed['tipo_crime'].nunique())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Salvar metadados\n",
    "metadata_path = DATA_PROCESSED_DIR / f'metadata_transformacao_{timestamp}.json'\n",
    "with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata_transformacao, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"‚úÖ Metadados salvos em: {metadata_path}\")\n",
    "print(f\"\\nüìã Resumo da Transforma√ß√£o:\")\n",
    "print(json.dumps(metadata_transformacao, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d7a40f",
   "metadata": {},
   "source": [
    "## 13. Resumo e Pr√≥ximos Passos\n",
    "\n",
    "### ‚úÖ Resumo da Transforma√ß√£o\n",
    "\n",
    "Neste notebook, realizamos as seguintes transforma√ß√µes:\n",
    "\n",
    "1. ‚úÖ **Padroniza√ß√£o de Nomes de Colunas** - Converteu para min√∫sculas, removeu acentos e caracteres especiais\n",
    "2. ‚úÖ **Remo√ß√£o de Duplicatas** - Identificou e removeu registros duplicados\n",
    "3. ‚úÖ **Tratamento de Valores Ausentes** - Preencheu valores nulos com zeros\n",
    "4. ‚úÖ **Categoriza√ß√£o de Crimes** - Agrupou tipos de crime em categorias (Violentos, Patrimoniais, Tr√¢nsito, Outros)\n",
    "5. ‚úÖ **C√°lculo da Taxa de Criminalidade** - Criou coluna `taxa_criminalidade` por 100k habitantes\n",
    "6. ‚úÖ **Agrega√ß√£o por Munic√≠pio** - Gerou dataset resumido por regi√£o\n",
    "7. ‚úÖ **Valida√ß√£o de Dados** - Verificou integridade e qualidade dos dados\n",
    "8. ‚úÖ **Visualiza√ß√µes** - Criou gr√°ficos para an√°lise explorat√≥ria\n",
    "9. ‚úÖ **Salvamento de Dados** - Exportou para CSV e Parquet em `data/processed/`\n",
    "10. ‚úÖ **Metadados** - Registrou informa√ß√µes sobre o processo de transforma√ß√£o\n",
    "\n",
    "### üìä Resultados Obtidos\n",
    "\n",
    "- **Dados limpos e padronizados**\n",
    "- **Taxa de criminalidade por 100k habitantes calculada**\n",
    "- **Categoriza√ß√£o de crimes aplicada**\n",
    "- **Dados prontos para an√°lise e carga**\n",
    "\n",
    "### üìù Pr√≥ximos Passos\n",
    "\n",
    "1. **Carga (Load)**: Execute o notebook `3_carga.ipynb` para carregar os dados em um banco de dados\n",
    "2. **An√°lise**: Use o notebook `4_analise_dados.ipynb` para an√°lises explorat√≥rias avan√ßadas\n",
    "3. **Visualiza√ß√µes**: Crie dashboards e relat√≥rios com os dados processados\n",
    "\n",
    "### üìÇ Arquivos Gerados\n",
    "\n",
    "- `data/processed/dados_processados_ssp_YYYYMMDD.csv` - Dados completos em CSV\n",
    "- `data/processed/dados_processados_ssp_YYYYMMDD.parquet` - Dados em formato Parquet\n",
    "- `data/processed/dados_agregados_municipio_YYYYMMDD.csv` - Dados agregados por munic√≠pio\n",
    "- `data/processed/metadata_transformacao_YYYYMMDD.json` - Metadados do processo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d661cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar todos os arquivos criados\n",
    "print(\"=\"*60)\n",
    "print(\"üìÇ ARQUIVOS CRIADOS NA TRANSFORMA√á√ÉO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìÅ Diret√≥rio: {DATA_PROCESSED_DIR}\\n\")\n",
    "for file in sorted(DATA_PROCESSED_DIR.glob('*')):\n",
    "    size_kb = file.stat().st_size / 1024\n",
    "    print(f\"  üìÑ {file.name:<50} ({size_kb:,.2f} KB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ TRANSFORMA√á√ÉO CONCLU√çDA COM SUCESSO!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüéØ Dados transformados e prontos para:\")\n",
    "print(\"   1. Carga em banco de dados (notebook 3_carga.ipynb)\")\n",
    "print(\"   2. An√°lise explorat√≥ria avan√ßada (notebook 4_analise_dados.ipynb)\")\n",
    "print(\"   3. Cria√ß√£o de dashboards e visualiza√ß√µes\")\n",
    "print(\"\\nüöÄ Pr√≥ximo passo: Execute o notebook '3_carga.ipynb'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
